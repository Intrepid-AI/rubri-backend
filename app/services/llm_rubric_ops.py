import os
import json
import uuid
from typing import Dict, List, Tuple, Optional, Any
from functools import lru_cache
from dotenv import load_dotenv
load_dotenv()

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_core.load import dumpd, load
from langchain_core.messages import messages_from_dict

from app.llm_client_ops import LLM_Client_Ops
from app.logger import get_logger
from app.constants import Constants
from app.db_ops import crud
from app.db_ops.models import Document
from app.api.v1.datamodels import RubricChatRequest

logger = get_logger(__name__)

@lru_cache(maxsize=None)
def get_llm_instance() -> LLM_Client_Ops:
    try:
        logger.debug("Initializing LLM instance with provider 'gemini'")
        llm_client = LLM_Client_Ops(provider_name="gemini")
        if llm_client.health_check():
            logger.info("LLM health check passed. LLM instance ready.")
            return llm_client
        else:
            logger.error("LLM health check failed")
            raise Exception("LLM health check failed")
    except Exception as e:
        logger.error(f"Error initializing LLM instance: {e}")
        raise

class PromptTemplateLoader:
    def __init__(self, prompt_templates_dir: str = Constants.PROMPTS_DIR.value):
        self.prompt_templates_dir = prompt_templates_dir
        logger.debug(f"PromptTemplateLoader initialized with directory: {self.prompt_templates_dir}")
        if not os.path.exists(self.prompt_templates_dir):
            logger.error(f"Prompt templates directory not found: {self.prompt_templates_dir}")
            raise FileNotFoundError

    def load_template(self, scenario_path: str) -> str:
        filepath = os.path.join(self.prompt_templates_dir, scenario_path)
        try:
            logger.debug(f"Loading prompt template: {filepath}")
            with open(filepath, "r") as f:
                prompt_content = f.read()
                logger.info(f"Loaded prompt template {scenario_path}: {filepath}")
                return prompt_content
        except FileNotFoundError:
            logger.error(f"Prompt template not found: {filepath}")
            raise

class RubricGenerator:
    def __init__(self, db):
        logger.debug("Initializing RubricGenerator")
        self.llm_client = get_llm_instance()
        self.prompt_loader = PromptTemplateLoader()
        self.db = db

    def generate_rubric(self, jd: Document, resume: Document = None) -> Dict[str, Any]:
        logger.info(f"Generating rubric for JD: {jd.doc_id} Resume: {resume.doc_id if resume else None}")

        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant for generating rubrics."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")  # This is key - use the {input} placeholder here
        ])

        memory = ConversationBufferMemory(return_messages=True, memory_key="history")
        conversation_chain = ConversationChain(
            llm=self.llm_client.llm_client,
            prompt=prompt,
            memory=memory,
            verbose=True
        )

        if resume:
            prompt_template_path = "rubric_jd_res.md"
            logger.debug(f"Loading prompt template for JD+Resume: {prompt_template_path}")
            prompt_content_tmp = self.prompt_loader.load_template(prompt_template_path)
            user_input = prompt_content_tmp.format(job_description=jd.extracted_text, resume=resume.extracted_text)
        else:
            prompt_template_path = "rubric_jd.md"
            logger.debug(f"Loading prompt template for JD only: {prompt_template_path}")
            prompt_content_tmp = self.prompt_loader.load_template(prompt_template_path)
            user_input = prompt_content_tmp.format(job_description=jd.extracted_text)

        logger.debug("Calling LLM to generate rubric response")
        response = conversation_chain.predict(input=user_input)
        logger.info("Rubric response generated by LLM")

        history_messages = conversation_chain.memory.chat_memory.messages
        serialized_messages = [dumpd(msg) for msg in history_messages]

        logger.debug("Saving rubric and conversation to database")
        rubric_record = crud.create_rubric(
            db=self.db,
            content=response,
            conversation=serialized_messages,
            jd_document_id=jd.doc_id,
            resume_document_id=resume.doc_id if resume else None
        )
        logger.info(f"Rubric record created with ID: {rubric_record.rubric_id}")

        return rubric_record

    def rubric_chat(self, chat_request : RubricChatRequest) -> Dict[str, Any]:


        logger.info(f"Chatting with rubric ID: {chat_request.rubric_id} \
                    Message: {chat_request.message}")

        rubric_record = crud.get_rubric(db=self.db, rubric_id=chat_request.rubric_id)

        if not rubric_record:
            logger.error(f"Rubric not found for ID: {chat_request.rubric_id}")
            raise ValueError(f"Rubric not found for ID: {chat_request.rubric_id}")

        logger.debug(f"Rubric found: {rubric_record.rubric_id}")

        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant for generating rubrics."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")
        ])

        memory = ConversationBufferMemory(return_messages=True, memory_key="history")

        try:
            saved_history = rubric_record.conversation
            logger.debug(f"Loaded conversation history: {saved_history}")
        except Exception as e:
            logger.error(f"Error loading conversation history: {e}")
            saved_history = None

        if saved_history:
            logger.debug("Restoring previous conversation history to memory")
            loaded_messages = [load(msg_dict) for msg_dict in saved_history]
            memory.chat_memory.messages = loaded_messages

        conversation_chain = ConversationChain(
            llm=self.llm_client.llm_client,
            prompt=prompt,
            memory=memory,
            verbose=True
        )

        # Continue the conversation
        logger.debug("Calling LLM to continue conversation for rubric modification")
        response = conversation_chain.predict(input=chat_request.message)
        logger.info("Received modified rubric response from LLM")

        # Get updated conversation history
        history_messages = conversation_chain.memory.chat_memory.messages
        serialized_messages = [dumpd(msg) for msg in history_messages]

        # Update rubric in database
        logger.debug("Updating rubric in database with new conversation and response")

        updated_rubric = crud.update_rubric_via_chat(
            db=self.db,
            rubric_id=rubric_record.rubric_id,
            content=response,
            conversation=serialized_messages
        )
        logger.info(f"Rubric record updated via chat. ID: {updated_rubric.rubric_id}")

        return updated_rubric

if __name__ == "__main__":
    from app.db_ops.database import SessionLocal
    import pprint
    from uuid import uuid4

    # Pretty printer for better output formatting
    pp = pprint.PrettyPrinter(indent=2)
    db = SessionLocal()
    
    try:
        logger.info("Starting RubricGenerator main test block")
        
        # Create test documents
        logger.debug("Creating test JD document")
        jd_doc = Document(
            doc_id=str(uuid4()),
            filename=f"{uuid4()}_jd.txt",
            original_filename="sample_jd.txt",
            file_path="/tmp/sample_jd.txt",
            content_type="text/plain",
            document_type="jd",
            extracted_text="""
            Senior Software Engineer Position
            Requirements:
            - 5+ years experience in Python development
            - Strong background in web frameworks (Django/Flask)
            - Experience with cloud platforms (AWS/GCP)
            - Knowledge of CI/CD practices
            """
        )

        logger.debug("Creating test Resume document")
        resume_doc = Document(
            doc_id=str(uuid4()),
            filename=f"{uuid4()}_resume.txt",
            original_filename="sample_resume.txt",
            file_path="/tmp/sample_resume.txt",
            content_type="text/plain",
            document_type="resume",
            extracted_text="""
            John Smith
            Senior Software Engineer
            
            Experience:
            - 7 years Python development
            - Expert in Django and Flask
            - AWS certified developer
            - Implemented CI/CD pipelines for multiple projects
            """
        )

        # Add documents to database
        logger.debug("Adding documents to database")
        db.add(jd_doc)
        db.add(resume_doc)
        db.commit()
        logger.info(f"Created test JD Document: {jd_doc.doc_id}")
        logger.info(f"Created test Resume Document: {resume_doc.doc_id}")

        # Initialize RubricGenerator
        logger.debug("Initializing RubricGenerator")
        rubric_generator = RubricGenerator(db=db)

        # Test rubric generation with both documents
        logger.info("Testing rubric generation with both JD and Resume")
        result_with_resume = rubric_generator.generate_rubric(jd=jd_doc, resume=resume_doc)
        logger.debug("Printing rubric with resume result:")
        pp.pprint(result_with_resume.__dict__)

        # Test rubric generation with only JD
        logger.info("Testing rubric generation with only JD")
        result_without_resume = rubric_generator.generate_rubric(jd=jd_doc)
        logger.debug("Printing rubric without resume result:")
        pp.pprint(result_without_resume.__dict__)

        # Test rubric chat/modification
        logger.info("Testing rubric chat modification")
        chat_request = RubricChatRequest(
            rubric_id=result_with_resume.rubric_id,
            message="Can you provide more details about the required cloud experience?"
        )
        
        modified_rubric = rubric_generator.rubric_chat(chat_request)
        logger.debug("Printing modified rubric result:")
        pp.pprint(modified_rubric)

    except FileNotFoundError as e:
        logger.error(f"Template file not found: {e}")
    except ValueError as e:
        logger.error(f"Invalid input or data: {e}")
    except Exception as e:
        logger.error(f"Unexpected error in main: {str(e)}", exc_info=True)
    finally:
        logger.info("Cleaning up database session")
        db.close()