import os
import json
import uuid
from typing import Dict, List, Tuple, Optional, Any
from functools import lru_cache
from dotenv import load_dotenv
load_dotenv()

from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain_core.load import dumpd, load
from langchain_core.messages import messages_from_dict

from app.llm_client_ops import LLM_Client_Ops
from app.logger import get_logger
from app.constants import Constants
from app.db_ops import crud
from app.db_ops.models import Document

logger = get_logger(__name__)

@lru_cache(maxsize=None)
def get_llm_instance() -> LLM_Client_Ops:
    try:
        logger.debug("Initializing LLM instance with provider 'gemini'")
        llm_client = LLM_Client_Ops(provider_name="gemini")
        if llm_client.health_check():
            logger.info("LLM health check passed. LLM instance ready.")
            return llm_client
        else:
            logger.error("LLM health check failed")
            raise Exception("LLM health check failed")
    except Exception as e:
        logger.error(f"Error initializing LLM instance: {e}")
        raise

class PromptTemplateLoader:
    def __init__(self, prompt_templates_dir: str = Constants.PROMPTS_DIR.value):
        self.prompt_templates_dir = prompt_templates_dir
        logger.debug(f"PromptTemplateLoader initialized with directory: {self.prompt_templates_dir}")
        if not os.path.exists(self.prompt_templates_dir):
            logger.error(f"Prompt templates directory not found: {self.prompt_templates_dir}")
            raise FileNotFoundError

    def load_template(self, scenario_path: str) -> str:
        filepath = os.path.join(self.prompt_templates_dir, scenario_path)
        try:
            logger.debug(f"Loading prompt template: {filepath}")
            with open(filepath, "r") as f:
                prompt_content = f.read()
                logger.info(f"Loaded prompt template {scenario_path}: {filepath}")
                return prompt_content
        except FileNotFoundError:
            logger.error(f"Prompt template not found: {filepath}")
            raise

class RubricGenerator:
    def __init__(self, db):
        logger.debug("Initializing RubricGenerator")
        self.llm_client = get_llm_instance()
        self.prompt_loader = PromptTemplateLoader()
        self.db = db

    def generate_rubric(self, jd: Document, resume: Document = None) -> Dict[str, Any]:
        logger.info(f"Generating rubric for JD: {jd.doc_id} Resume: {resume.doc_id if resume else None}")
        # Create conversation chain with appropriate system message
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant for generating rubrics."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")  # This is key - use the {input} placeholder here
        ])

        memory = ConversationBufferMemory(return_messages=True, memory_key="history")
        conversation_chain = ConversationChain(
            llm=self.llm_client.llm_client,
            prompt=prompt,
            memory=memory,
            verbose=True
        )

        # Prepare the user message with the appropriate template
        if resume:
            prompt_template_path = "rubric_jd_res.md"
            logger.debug(f"Loading prompt template for JD+Resume: {prompt_template_path}")
            prompt_content_tmp = self.prompt_loader.load_template(prompt_template_path)
            user_input = prompt_content_tmp.format(job_description=jd.extracted_text, resume=resume.extracted_text)
        else:
            prompt_template_path = "rubric_jd.md"
            logger.debug(f"Loading prompt template for JD only: {prompt_template_path}")
            prompt_content_tmp = self.prompt_loader.load_template(prompt_template_path)
            user_input = prompt_content_tmp.format(job_description=jd.extracted_text)

        logger.debug("Calling LLM to generate rubric response")
        response = conversation_chain.predict(input=user_input)
        logger.info("Rubric response generated by LLM")

        # Save conversation history
        history_messages = conversation_chain.memory.chat_memory.messages
        serialized_messages = [dumpd(msg) for msg in history_messages]

        # Save to database
        logger.debug("Saving rubric and conversation to database")
        rubric_record = crud.create_rubric(
            db=self.db,
            content=response,
            conversation=serialized_messages,
            jd_document_id=jd.doc_id,
            resume_document_id=resume.doc_id if resume else None
        )
        logger.info(f"Rubric record created with ID: {rubric_record.rubric_id}")

        return rubric_record

    def rubric_modifications(self, conversation_id: str, user_message: str) -> Dict[str, Any]:
        logger.info(f"Modifying rubric with conversation_id: {conversation_id}")
        # Retrieve the existing rubric record
        rubric_record = crud.get_rubric(db=self.db, rubric_id=conversation_id)
        if not rubric_record:
            logger.error(f"Rubric not found for ID: {conversation_id}")
            raise ValueError(f"Rubric not found for ID: {conversation_id}")

        # Create conversation chain with the correct prompt structure
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant for generating rubrics."),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{input}")  # Use the {input} placeholder here
        ])

        memory = ConversationBufferMemory(return_messages=True, memory_key="history")
        
        # Restore previous messages to memory
        saved_history = rubric_record.content.get('conversation_history', [])
        if saved_history:
            logger.debug("Restoring previous conversation history to memory")
            loaded_messages = [load(msg_dict) for msg_dict in saved_history]
            memory.chat_memory.messages = loaded_messages

        conversation_chain = ConversationChain(
            llm=self.llm_client.llm_client,
            prompt=prompt,
            memory=memory,
            verbose=True
        )

        # Continue the conversation
        logger.debug("Calling LLM to continue conversation for rubric modification")
        response = conversation_chain.predict(input=user_message)
        logger.info("Received modified rubric response from LLM")

        # Get updated conversation history
        history_messages = conversation_chain.memory.chat_memory.messages
        serialized_messages = [dumpd(msg) for msg in history_messages]

        # Update rubric in database
        logger.debug("Updating rubric in database with new conversation and response")
        updated_rubric = crud.update_rubric_via_chat(
            db=self.db,
            rubric_id=rubric_record.id,
            content={
                "response": response,
                "conversation_history": serialized_messages
            },
            message=user_message
        )
        logger.info(f"Rubric record updated via chat. ID: {updated_rubric.id}")

        return {
            "response": response,
            "conversation_id": conversation_id,
            "rubric_id": updated_rubric.id
        }

if __name__ == "__main__":
    from app.db_ops.database import SessionLocal
    db = SessionLocal()
    try:
        logger.info("Starting RubricGenerator main test block")
        # Create example Document objects for JD and Resume
        jd_doc = Document(
            doc_id=str(uuid.uuid4()),
            filename=str(uuid.uuid4()) + "jd.txt",
            original_filename="jd.txt",
            file_path="/tmp/jd.txt",
            content_type="text/plain",
            document_type="jd",
            extracted_text="We are looking for a highly skilled and experienced software engineer to join our team. The ideal candidate will have a strong background in Python and experience with various frameworks. Responsibilities include designing, developing, and testing software applications."
        )
        resume_doc = Document(
            doc_id=str(uuid.uuid4()),
            filename=str(uuid.uuid4()) + "resume.txt",
            original_filename="resume.txt",
            file_path="/tmp/resume.txt",
            content_type="text/plain",
            document_type="resume",
            extracted_text="John Doe\nSoftware Engineer\n10 years of experience in software development. Proficient in Python, Java, and C++. Experience with various frameworks and technologies."
        )
        # Add to DB for completeness (optional, can be commented out if not needed)
        db.add(jd_doc)
        db.add(resume_doc)
        db.commit()
        logger.info(f"Created test JD Document: {jd_doc.doc_id}")
        logger.info(f"Created test Resume Document: {resume_doc.doc_id}")

        rubric_generator = RubricGenerator(db=db)

        logger.info("Generating rubric with resume Document objects")
        result_with_resume = rubric_generator.generate_rubric(jd=jd_doc, resume=resume_doc)
        print("Rubric with Resume:", result_with_resume)

        logger.info("Generating rubric with only JD Document object")
        result_without_resume = rubric_generator.generate_rubric(jd=jd_doc)
        print("Rubric without Resume:", result_without_resume)

        logger.info("Testing rubric modification")
        conversation_id = result_with_resume["rubric_id"]
        user_message = "Can you add more details about the experience required?"
        modified_rubric = rubric_generator.rubric_modifications(conversation_id=conversation_id, user_message=user_message)
        print("Modified Rubric:", modified_rubric)

    except Exception as e:
        logger.error(f"An error occurred in main: {e}")
    finally:
        db.close()
        logger.info("Database session closed in main block")